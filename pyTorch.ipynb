{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dc73a6",
   "metadata": {},
   "source": [
    "pyTorch Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab44a390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7f001",
   "metadata": {},
   "source": [
    "Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83df743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordleDataset(Dataset):\n",
    "    def __init__(self,data_dir,targetToClass,transform=None):\n",
    "        self.data = []\n",
    "        with open(data_dir,'r') as f:\n",
    "            for line in f:\n",
    "                lineData = line.split()\n",
    "                target = lineData[0]\n",
    "                guesses = lineData[1:len(lineData)]\n",
    "\n",
    "                #Tokenize the inputs and convert to tensors\n",
    "                \n",
    "                target = targetToClass[target]\n",
    "                for i in range(len(guesses)):\n",
    "                    guesses[i] = targetToClass[guesses[i]]\n",
    "                targetTensor = torch.tensor(target)\n",
    "                guessTensor = torch.tensor(guesses)\n",
    "                self.data.append([targetTensor,guessTensor])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba9da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToNum = {}\n",
    "numToWord = {}\n",
    "index = 0\n",
    "with open(\"words.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        lineData = line.split()\n",
    "        numToWord.update({index:lineData[0]})\n",
    "        wordToNum.update({lineData[0]:index})\n",
    "        index += 1\n",
    "\n",
    "wordleSet = wordleDataset(\"TrainingData.txt\",wordToNum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e08cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(wordleSet, batch_size=32, shuffle=True)\n",
    "for outputData,inputData in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7813d7a",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00290ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5314e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork(nn.Module):\n",
    "    def __init__(self,num_in,h1,h2,num_out):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_in,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.out = nn.Linear(h2,num_out)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        #Inputs into fc1 through relu function (f(x) = x if x>0,else 0)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eccf43c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(234524)\n",
    "\n",
    "model = neuralNetwork(10,256,256,15099)\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd8bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "critereon = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625000\n",
      "0 100\n",
      "1508.43963495625\n",
      "1 100\n",
      "1508.4396343953124\n",
      "2 100\n",
      "1508.4396345921875\n",
      "3 100\n",
      "1508.439634425\n",
      "4 100\n",
      "1508.4396350359375\n",
      "5 100\n",
      "1508.43963375\n",
      "6 100\n"
     ]
    }
   ],
   "source": [
    "epochNum = 100\n",
    "losses,valLosses = [],[]\n",
    "\n",
    "print(len(dataloader.dataset))\n",
    "\n",
    "for i in range(epochNum):\n",
    "    print(i,epochNum)\n",
    "    \n",
    "    model.train()\n",
    "    curLoss = 0\n",
    "    for output,input in dataloader:\n",
    "        output,input = output.to(device), input.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        input = input.float()\n",
    "\n",
    "        modelOutputs = model(input)\n",
    "        loss = critereon(modelOutputs,output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        curLoss += loss.item()*len(input)\n",
    "    totalLoss = curLoss / len(dataloader.dataset)\n",
    "    losses.append(totalLoss)\n",
    "\n",
    "    #Evaluation\n",
    "    model.eval()\n",
    "    curLoss=0\n",
    "    with torch.no_grad():\n",
    "        for output,input in dataloader:\n",
    "            output,input = output.to(device), input.to(device)\n",
    "            input = input.float()\n",
    "\n",
    "            modelOutputs = model(input)\n",
    "            loss = critereon(modelOutputs,output)\n",
    "            curLoss += loss.item() * len(input)\n",
    "    valLoss = curLoss / len(dataloader.dataset)\n",
    "    valLosses.append(curLoss)\n",
    "\n",
    "    print(totalLoss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
