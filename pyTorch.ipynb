{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dc73a6",
   "metadata": {},
   "source": [
    "pyTorch Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ab44a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7f001",
   "metadata": {},
   "source": [
    "Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c83df743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordleDataset(Dataset):\n",
    "    def __init__(self,data_dir,targetToClass,transform=None):\n",
    "        self.data = []\n",
    "        with open(data_dir,'r') as f:\n",
    "            for line in f:\n",
    "                lineData = line.split()\n",
    "                target = lineData[0]\n",
    "                guesses = lineData[1:len(lineData)]\n",
    "\n",
    "                #Tokenize the inputs and convert to tensors\n",
    "                \n",
    "                target = targetToClass[target]\n",
    "                for i in range(len(guesses)):\n",
    "                    guesses[i] = targetToClass[guesses[i]]\n",
    "                targetTensor = torch.tensor(target)\n",
    "                guessTensor = torch.tensor(guesses)\n",
    "                self.data.append([targetTensor,guessTensor])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2ba9da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToNum = {}\n",
    "numToWord = {}\n",
    "index = 0\n",
    "with open(\"words.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        lineData = line.split()\n",
    "        numToWord.update({index:lineData[0]})\n",
    "        wordToNum.update({lineData[0]:index})\n",
    "        index += 1\n",
    "\n",
    "wordleSet = wordleDataset(\"TrainingData.txt\",wordToNum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8e08cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(wordleSet, batch_size=32, shuffle=True)\n",
    "for outputData,inputData in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7813d7a",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5314e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork(nn.Module):\n",
    "    def __init__(self,num_in,h1,h2,num_out):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_in,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.out = nn.Linear(h2,num_out)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        #Inputs into fc1 through relu function (f(x) = x if x>0,else 0)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "eccf43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(234524)\n",
    "\n",
    "model = neuralNetwork(10,256,256,15099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "acd8bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "critereon = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n",
      "35.656976654052734\n",
      "1 100\n",
      "9.544639926147461\n",
      "2 100\n",
      "9.44356936126709\n",
      "3 100\n",
      "9.395314634399414\n",
      "4 100\n",
      "9.370790156860352\n",
      "5 100\n",
      "9.357799973449707\n",
      "6 100\n",
      "9.351068764648437\n",
      "7 100\n",
      "9.34757723388672\n",
      "8 100\n",
      "9.345680192565919\n",
      "9 100\n",
      "9.344569777526855\n",
      "10 100\n",
      "9.344097963562012\n",
      "11 100\n",
      "9.343771035461426\n",
      "12 100\n",
      "9.343572631225586\n",
      "13 100\n",
      "9.343468377990723\n",
      "14 100\n",
      "9.34359139465332\n",
      "15 100\n",
      "9.34335033782959\n",
      "16 100\n",
      "9.34339220336914\n",
      "17 100\n",
      "9.34335113067627\n",
      "18 100\n",
      "9.343204164123534\n",
      "19 100\n",
      "9.34341103149414\n",
      "20 100\n",
      "9.343266569519043\n",
      "21 100\n",
      "9.343094058532715\n",
      "22 100\n",
      "9.343030309448242\n",
      "23 100\n",
      "9.343252382202149\n",
      "24 100\n",
      "9.343185375976562\n",
      "25 100\n",
      "9.343266513671875\n",
      "26 100\n",
      "9.343257315063477\n",
      "27 100\n",
      "9.343205603637696\n",
      "28 100\n",
      "9.343257147216796\n",
      "29 100\n",
      "9.34313479309082\n",
      "30 100\n"
     ]
    }
   ],
   "source": [
    "epochNum = 100\n",
    "losses,valLosses = [],[]\n",
    "for i in range(epochNum):\n",
    "    print(i,epochNum)\n",
    "    \n",
    "    model.train()\n",
    "    curLoss = 0\n",
    "    index=0\n",
    "    for output,input in dataloader:\n",
    "        index+=1\n",
    "        optimizer.zero_grad()\n",
    "        input = input.float()\n",
    "\n",
    "        modelOutputs = model(input)\n",
    "        loss = critereon(modelOutputs,output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        curLoss += loss.item()*len(input)\n",
    "    totalLoss = curLoss / len(dataloader.dataset)\n",
    "    losses.append(totalLoss)\n",
    "\n",
    "    #Evaluation\n",
    "    model.eval()\n",
    "    curLoss=0\n",
    "    with torch.no_grad():\n",
    "        for output,input in dataloader:\n",
    "            input = input.float()\n",
    "\n",
    "            modelOutputs = model(input)\n",
    "            loss = critereon(modelOutputs,output)\n",
    "            curLoss += loss.item() * len(input)\n",
    "    valLoss = curLoss / len(dataloader.dataset)\n",
    "    valLosses.append(curLoss)\n",
    "\n",
    "    print(totalLoss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
